{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbf1def",
   "metadata": {},
   "source": [
    "# Analysis of NHANES data - case studies\n",
    "\n",
    "In this notebook, we illustrate several basic techniques for exploring data using methods for understanding multivariate relationships.  The statistical methods discussed here will parallel the methods discussed in the multivariate methods section of the course, and build on the univariate analysis discussed earlier.  As with the univariate notebook, we use here the 2015-2016 wave of the [NHANES](https://www.cdc.gov/nchs/nhanes/index.htm) study for illustration.\n",
    "\n",
    "Many of the analyses presented in this notebook use the Matplotlib and Seaborn libraries for data visualization.  These are very powerful tools that give you a vast number of options when constructing plots.  We will not explain every option to every function in the examples below. You can use the [Matplotlib](https://matplotlib.org/users/index.html) and [Seaborn](https://seaborn.pydata.org/tutorial.html) documentation to fully understand the options, and you can experiment with these and other plots on your own to get a better sense of what can be done.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c5d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/modified_NHANES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be39aa",
   "metadata": {},
   "source": [
    "### Quantitative bivariate data\n",
    "\n",
    "Bivariate data arise when every \"unit of analysis\" (e.g. a person in the NHANES dataset) is assessed with respect to two traits (the NHANES subjects were assessed for many more than two traits, but we can consider two traits at a time here).  \n",
    "\n",
    "A scatterplot is a very common and easily-understood visualization of quantitative bivariate data.  Below we make a scatterplot of arm length against leg length.  This means that arm length ([BMXARML](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm#BMXARML)) is plotted on the vertical axis and leg length ([BMXLEG](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm#BMXLEG)) is plotted on the horizontal axis).  We see a positive dependence between the two measures -- people with longer arms tend to have longer legs, and vice-versa.  However it is far from a perfect relationship.\n",
    "\n",
    "In a scatterplot with more than around 100 points, \"overplotting\" becomes an issue.  This means that many points fall on top of each other in the plot, which obscures relationships in the middle of the distribution and over-emphasizes the extremes.  One way to mitigate overplotting is to use an \"alpha\" channel to make the points semi-transparent, as we have done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fffa1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=\"BMXLEG\", y=\"BMXARML\", data=df, fit_reg=False, scatter_kws={\"alpha\": 0.2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441e5f2",
   "metadata": {},
   "source": [
    "\n",
    "### Heterogeneity and stratification\n",
    "Most human characteristics are complex -- they vary by gender, age, ethnicity, and other factors. This type of variation is often referred to as \"heterogeneity\". When such heterogeneity is present, it is usually productive to explore the data more deeply by stratifying on relevant factors, as we did in the univariate analyses.\n",
    "\n",
    "Below, we continue to probe the relationship between leg length and arm length, stratifying first by gender, then by gender and ethnicity. The gender-stratified plot indicates that men tend to have somewhat longer arms and legs than women -- this is reflected in the fact that the cloud of points on the left is shifted slightly up and to the right relative to the cloud of points on the right. In addition, the correlation between arm length and leg length appears to be somewhat weaker in women than in men.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(df, col=\"RIAGENDRx\").map(plt.scatter, \"BMXLEG\", \"BMXARML\", alpha=0.4).add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d35278",
   "metadata": {},
   "source": [
    "Consistent with the scatterplot, a slightly weaker correlation between arm length and leg length in women (compared to men) can be seen by calculating the correlation coefficient separately within each gender.\n",
    "\n",
    "The 'corr' method of a dataframe calculates the correlation coefficients for every pair of variables in the dataframe. This method returns a \"correlation matrix\", which is a table containing the correlations between every pair of variables in the data set. Note that the diagonal of a correlation matrix always contains 1's, since a variable always has correlation 1 with itself. The correlation matrix is also symmetric around this diagonal, since the correlation between two variables 'X' and 'Y' does not depend on the order in which we consider the two variables.\n",
    "\n",
    "In the results below, we see that the correlation between leg length and arm length in men is 0.50, while in women the correlation is 0.43.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df.RIAGENDRx==\"Female\", [\"BMXLEG\", \"BMXARML\"]].dropna().corr())\n",
    "print(df.loc[df.RIAGENDRx==\"Male\", [\"BMXLEG\", \"BMXARML\"]].dropna().corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec4f84",
   "metadata": {},
   "source": [
    "Next we look to stratifying the data by both gender and ethnicity.  This results in 2 x 5 = 10 total strata, since there are 2 gender strata and 5 ethnicity strata. These scatterplots reveal differences in the means as well a diffrences in the degree of association (correlation) between different pairs of variables.  We see that although some ethnic groups tend to have longer/shorter arms and legs than others, the relationship between arm length and leg length within genders is roughly similar across the ethnic groups.  \n",
    "\n",
    "One notable observation is that ethnic group 5, which consists of people who report being multi-racial or are of any race not treated as a separate group (due to small sample size), the correlation between arm length and leg length is stronger, especially for men.  This is not surprising, as greater heterogeneity can allow correlations to emerge that are indiscernible in more homogeneous data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600dc40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(df, col=\"RIDRETH1\",  row=\"RIAGENDRx\").map(plt.scatter, \"BMXLEG\", \"BMXARML\", alpha=0.5).add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(df, col=\"RIDRETH1x\",  row=\"RIAGENDRx\").map(plt.scatter, \"BMXLEG\", \"BMXARML\", alpha=0.5).add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cbc7a1",
   "metadata": {},
   "source": [
    "### Categorical bivariate data\n",
    "\n",
    "In this section we discuss some methods for working with bivariate data that are categorical.  We can start with a contingency table, which counts the number of people having each combination of two factors.  To illustrate, we will consider the NHANES variables for marital status and education level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24018bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.crosstab(df.DMDEDUC2x, df.DMDMARTLx)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cfc26f",
   "metadata": {},
   "source": [
    "Create a new data set that omits missing data and people who responded \"Don't know\" or who refused to answer these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = df.loc[(df.DMDEDUC2 <6) & (df.DMDMARTL <7), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.crosstab(db.DMDEDUC2x, db.DMDMARTLx)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e6fbe",
   "metadata": {},
   "source": [
    "# Confidence Intervals in python\n",
    "## Statistical Inference with Confidence Intervals\n",
    "\n",
    "\n",
    "### Why Confidence Intervals?\n",
    "\n",
    "Confidence intervals are a calculated range or boundary around a parameter or a statistic that is supported mathematically with a certain level of confidence.  For example, we can estimated, with 95% confidence, that the population proportion of parents with a toddler that use a car seat for all travel with their toddler is somewhere between 82.2% and 87.7%.\n",
    "\n",
    "This is *__different__* than having a 95% probability that the true population proportion is within our confidence interval.\n",
    "\n",
    "Essentially, if we were to repeat this process, 95% of our calculated confidence intervals would contain the true proportion.\n",
    "\n",
    "### How are Confidence Intervals Calculated?\n",
    "\n",
    "Our equation for calculating confidence intervals is as follows:\n",
    "\n",
    "$$Best\\ Estimate \\pm Margin\\ of\\ Error$$\n",
    "\n",
    "Where the *Best Estimate* is the **observed population proportion or mean** and the *Margin of Error* is the **t-multiplier**.\n",
    "\n",
    "The t-multiplier is calculated based on the degrees of freedom and desired confidence level.  For samples with more than 30 observations and a confidence level of 95%, the t-multiplier is 1.96\n",
    "\n",
    "The equation to create a 95% confidence interval can also be shown as:\n",
    "\n",
    "$$Population\\ Proportion\\ or\\ Mean\\ \\pm (t-multiplier *\\ Standard\\ Error)$$\n",
    "\n",
    "Lastly, the Standard Error is calculated differenly for population proportion and mean:\n",
    "\n",
    "$$Standard\\ Error \\ for\\ Population\\ Proportion = \\sqrt{\\frac{Population\\ Proportion * (1 - Population\\ Proportion)}{Number\\ Of\\ Observations}}$$\n",
    "\n",
    "$$Standard\\ Error \\ for\\ Mean = \\frac{Standard\\ Deviation}{\\sqrt{Number\\ Of\\ Observations}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5ba37",
   "metadata": {},
   "source": [
    "## Confidence intervals for one proportion\n",
    "\n",
    "In this section, we demonstrate the construction of confidence intervals for the proportion of people who smoke.  The specific definition of \"smoker\" used here ([SMQ020](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/SMQ_I.htm#SMQ020)) identifies a person as being a smoker if they self-report as having smoked 100 or more cigarettes in their lifetime.  It is more accurate to refer to this as a measure of \"lifetime smoking\" rather than \"current smoking\".  Recall that the definitions of these and other NHANES variables can be found using the NHANES code books, or by searching using the link below.\n",
    "\n",
    "https://wwwn.cdc.gov/nchs/nhanes/search/default.aspx\n",
    "\n",
    "We will calculate the proportions of smokers separately for females and for males.  Initially we can compare these two proportions and their corresponding confidence intervals informally, but later we will discuss methods to compare two proportions formally using confidence intervals.\n",
    "\n",
    "First we replace the numeric codes in the variables of interest with text labels, and set the rare answers other than \"yes\" and \"no\" to be missing (so they will automatically be omitted from all the analyses below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc76b86",
   "metadata": {},
   "source": [
    "### Recode SMQ020 into variable SMQ020y\n",
    " - Yes/No to 1/0 ( this will allow us to calculate percentages)\n",
    " - all other codes we will set to NA using np.nan\n",
    " \n",
    " so SMQ020 is coded \n",
    "  - 1 Yes\n",
    "  - 2 No\n",
    "  - 7 Refused\n",
    "  - 9 Don't know\n",
    "  \n",
    "  SMQ020y will change:\n",
    "   - 1 to 1\n",
    "   - 2 to 0\n",
    "   - 7 & 9 to np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe831ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMQ020y'] = df.SMQ020.replace({1: 1, 2: 0, 7: np.nan, 9: np.nan})\n",
    "dx = df[[\"SMQ020y\", \"RIAGENDRx\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b042a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dx.SMQ020y, dx.RIAGENDRx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = dx.groupby('RIAGENDRx').agg({'SMQ020y': [np.mean, np.size]})\n",
    "dz.columns = [\"Proportion\", \"Total_n\"] # The default column names are unclear, so we replace them here\n",
    "dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f5e95",
   "metadata": {},
   "source": [
    "Confidence intervals are closely connected to standard errors. Recall that the standard error essentially tells you how far you should expect an estimate to fall from the truth. A confidence interval is an interval that under repeated sampling covers the truth a defined proportion of the time. In most settings, this \"coverage probability\" is set to 95%.\n",
    "\n",
    "It turns out that in many settings, a 95% confidence interval can be constructed as the interval consisting of all points that are within two (or 1.96) standard errors of the point estimate. More concisely, the confidence interval approximately spans from e - 2•SE to e + 2•SE, where e is the point estimate and SE is the standard error.\n",
    "\n",
    "Since the standard error plays such an important role here, we calculate it separately first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dz.Proportion.Female # Female proportion\n",
    "n = dz.Total_n.Female # Total number of females\n",
    "se_female = np.sqrt(p * (1 - p) / n)\n",
    "\n",
    "print(p)\n",
    "print(se_female)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dz.Proportion.Female # Female proportion\n",
    "n = dz.Total_n.Female # Total number of females\n",
    "lcb = p - 1.96 * np.sqrt(p * (1 - p) / n)  \n",
    "ucb = p + 1.96 * np.sqrt(p * (1 - p) / n)  \n",
    "print(lcb, ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852bc99d",
   "metadata": {},
   "source": [
    "### Constructing Confidence Intervals for difference in Proportions or Means\n",
    "\n",
    "Now we have the proportions of male and female smokers. Suppose we wish to construct a 95% confidence interval for the difference in mean proportions of male and female smokers using these data. we can begin to calculate confidence intervals.  \n",
    "\n",
    "$$Best\\ Estimate \\pm Margin\\ of\\ Error$$\n",
    "\n",
    "Where the *Best Estimate* is the **observed population proportion or mean** from the sample and the *Margin of Error* is the **t-multiplier**.\n",
    "\n",
    "The equation to create a 95% confidence interval can also be shown as:\n",
    "\n",
    "$$Population\\ Proportion\\ or\\ Mean\\ \\pm (t-multiplier *\\ Standard\\ Error)$$\n",
    "\n",
    "The Standard Error (SE) is calculated differenly for population proportion and mean:\n",
    "\n",
    "$$Standard\\ Error \\ for\\ Population\\ Proportion = \\sqrt{\\frac{Population\\ Proportion * (1 - Population\\ Proportion)}{Number\\ Of\\ Observations}}$$\n",
    "\n",
    "$$Standard\\ Error \\ for\\ Mean = \\frac{Standard\\ Deviation}{\\sqrt{Number\\ Of\\ Observations}}$$\n",
    "\n",
    "Lastly, the standard error for **difference of population proportions and means** is:\n",
    "\n",
    "$$Standard\\ Error\\ for\\ Difference\\ of\\ Two\\ Population\\ Proportions\\ Or\\ Means = \\sqrt{(SE_{\\ 1})^2 + (SE_{\\ 2})^2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fdc46",
   "metadata": {},
   "source": [
    "### Difference of Two Population Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = .304845\n",
    "n = 2972\n",
    "se_female = np.sqrt(p * (1 - p)/n)\n",
    "se_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = .513258\n",
    "n = 2753\n",
    "se_male = np.sqrt(p * (1 - p)/ n)\n",
    "se_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c06aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_diff = np.sqrt(se_female**2 + se_male**2)\n",
    "se_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb95728",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = .513258 - .304845  \n",
    "lcb = d - 1.96 * se_diff\n",
    "ucb = d + 1.96 * se_diff\n",
    "(d, lcb, ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cf46f",
   "metadata": {},
   "source": [
    "### Difference of Two Population Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04357c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"RIAGENDRx\").agg({\"BMXBMI\": [np.mean, np.std, np.size]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7775f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_female = 7.753319 / np.sqrt(2976)\n",
    "sem_male = 6.252568 / np.sqrt(2759)\n",
    "(sem_female, sem_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_diff = np.sqrt(sem_female**2 + sem_male**2)\n",
    "sem_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82df71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 29.939946 - 28.778072\n",
    "lcb = d - 1.96 * sem_diff\n",
    "ucb = d + 1.96 * sem_diff\n",
    "(d, lcb, ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2727b2",
   "metadata": {},
   "source": [
    "\n",
    "### Confidence intervals for subpopulations\n",
    "Since smoking rates vary strongly with age, it might be more informative to stratify the data into homogeneous age bands and compare the proportions of female and male smokers within each age band. We can also calculate the 95% confidence interval for this difference within each age band. These data can be displayed as a plot, with the difference in proportions plotted as a curve. The confidence intervals can then be used to construct a \"confidence band\" around the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the smoking rates within age/gender groups\n",
    "df[\"agegrp\"] = pd.cut(df.RIDAGEYR, [18, 30, 40, 50, 60, 70, 80])\n",
    "pr = df.groupby([\"agegrp\", \"RIAGENDRx\"]).agg({\"SMQ020x\": lambda x: np.mean(x==\"Yes\")}).unstack()\n",
    "pr.columns = [\"Female\", \"Male\"]\n",
    "print(pr)\n",
    "# The number of people for each calculated proportion\n",
    "dn = df.groupby([\"agegrp\", \"RIAGENDRx\"]).agg({\"SMQ020x\": np.size}).unstack()\n",
    "dn.columns = [\"Female\", \"Male\"]\n",
    "print(dn)\n",
    "# Standard errors for each proportion\n",
    "se = np.sqrt(pr * (1 - pr) / dn)\n",
    "print(se)\n",
    "\n",
    "# Standard error for the difference in female/male smoking rates in every age band\n",
    "se_diff = np.sqrt(se.Female**2 + se.Male**2)\n",
    "print(se_diff)\n",
    "\n",
    "# Standard errors for the difference in smoking rates between genders, within age bands\n",
    "\n",
    "\n",
    "# The difference in smoking rates between genders\n",
    "pq = pr.Female - pr.Male\n",
    "print(pq)\n",
    "\n",
    "x = np.arange(pq.size)\n",
    "pp = sns.pointplot(x, pq.values, color='black')\n",
    "sns.pointplot(x, pq - 2*se_diff)\n",
    "sns.pointplot(x, pq + 2*se_diff)\n",
    "pp.set_xticklabels(pq.index)\n",
    "pp.set_xlabel(\"Age group\")\n",
    "pp.set_ylabel(\"Female - male smoking proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa338203",
   "metadata": {},
   "source": [
    "The plot above shows for each age band, the point estimate of the difference in smoking rates between genders (black dot), and the lower and upper end points of the 95% confidence interval (blue points). Based on this plot, we see that in the United States, smoking is more common in men than in women, not just overall, but also in every one of the age bands. The difference is largest for older people -- for people older than 60, the smoking rate for males is around 30 percentage points greater than the smoking rate for females, while for people younger than 30, the smoking rate for males is only around 15 percentage points greater than the smoking rate for females.\n",
    "\n",
    "Also note that the 95% confidence bands shown above are much wider than the 95% confidence intervals for the data that were not stratified by age. Stratifying by age leads to smaller sample sizes, which in turn results in wider confidence intervals.\n",
    "\n",
    "## Confidence intervals for the mean\n",
    "In this section, we discuss how to construct confidence intervals for the mean. First note that the proportion discussed above is also a mean -- for example, if the data are 0, 1, 0, then the mean is 1/3, which is also the proportion of 1's in the data. However the proportion has the special property that the variance is completely determined by the mean. That is why we constructed the standard errors for the sample proportion above using p•(1 - p) as the variance. In general, the variance of quantitative data will not be a function of the mean, as this is a very special property of binary data. Therefore, in general we must estimate the variance as a separate step after estimating the mean.\n",
    "\n",
    "To illustrate the construction of confidence intervals for the population mean of a quantitative variable, we will use the body mass inde (BMI) data from NHANES. To begin, we calculate the mean BMI for all women and for all men in the NHANES sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7adcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"RIAGENDRx\").agg({\"BMXBMI\": np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df['BMXBMI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb517ca",
   "metadata": {},
   "source": [
    "The numbers in the first column of the table above are estimates of the population mean BMI for all women and for all men in the United States (the population that the NHANES study represents). As with the sample proportions, these numbers are not exactly equal to the mean BMI for all women and men, they are only estimates. To establish the uncertainty for these estimates, we can use the standard errors for these two estimated means.\n",
    "\n",
    "The standard error for the mean based on an independent and identically distributed sample is equal to the standard deviation of the variable divided by the square root of the sample size. We next calculate all the relevant values needed to compute the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4511d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"RIAGENDRx\").agg({\"BMXBMI\": [np.mean, np.std, np.size]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f735a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_female = 7.753 / np.sqrt(2976)\n",
    "sem_male = 6.253 / np.sqrt(2759)\n",
    "print(sem_female, sem_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2427e",
   "metadata": {},
   "source": [
    "print(sem_female, sem_male)\n",
    "We see that the sample mean BMI for women is expected to be off by around 0.14 relative to the population mean BMI for women, and the sample mean BMI for men is expected to be off by around 0.12 relative to the population mean BMI for men.\n",
    "\n",
    "The standard error of the mean for women is slightly larger for women than for men. The reason for this is that even though the NHANES sample size for women is slightly larger than that for men, the data for women appears to be more spread out. The greater standard deviation for the female BMI values leads in turn to less precision when estimating the population mean BMI for females.\n",
    "\n",
    "As was the case for proportions, the 95% confidence interval for the mean can be calculated by taking the estimate plus and minus 2 (or 1.96) times the standard error. The 95% confidence interval for female BMI is thus calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcb_female = 29.94 - 1.96 * 7.753 / np.sqrt(2976)\n",
    "ucb_female = 29.94 + 1.96 * 7.753 / np.sqrt(2976)\n",
    "print(lcb_female, ucb_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa15cfe",
   "metadata": {},
   "source": [
    "### Confidence intervals for the difference between two means\n",
    "Now we turn to studying the difference between two means, taking the difference between mean female and male BMI for illustration. As discussed above, the standard error for the difference of two means taken from independent samples is sqrt(SE1^2 + SE2^2), where SE1 and SE2 are the standard errors for the two means being compared. Below we see that this gives us a value around 0.19 when comparing the female BMI to the male BMI. This is substantially larger than either the SEM for estimating the female mean (0.14) or the SEM for estimating the male mean (0.12). It is expected that the standard error for the difference between two means is greater than the standard errors for estimating a single mean, since the uncertainty of both gender-specific proportions impacts the statistic.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Confidence intervals for the difference between two means\n",
    "Now we turn to studying the difference between two means, taking the difference between mean female and male BMI for illustration. As discussed above, the standard error for the difference of two means taken from independent samples is sqrt(SE1^2 + SE2^2), where SE1 and SE2 are the standard errors for the two means being compared. Below we see that this gives us a value around 0.19 when comparing the female BMI to the male BMI. This is substantially larger than either the SEM for estimating the female mean (0.14) or the SEM for estimating the male mean (0.12). It is expected that the standard error for the difference between two means is greater than the standard errors for estimating a single mean, since the uncertainty of both gender-specific proportions impacts the statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e04fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_diff = np.sqrt(sem_female**2 + sem_male**2)\n",
    "sem_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c1776",
   "metadata": {},
   "source": [
    "We can can now construct a 95% confidence interval for the difference between the female and male mean BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18374d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_diff = 29.94 - 28.78\n",
    "lcb = bmi_diff - 2*sem_diff\n",
    "ucb = bmi_diff + 2*sem_diff\n",
    "(bmi_diff, lcb, ucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecebca3",
   "metadata": {},
   "source": [
    "This finding indicates that while the point estimate shows that the women in our sample have around 1.1 unit greater BMI than the men in our sample, the true difference between the mean for all women in the population and for all men in the population could fall between 0.79 and 1.53, and still be consistent with the observed data.\n",
    "\n",
    "**Age-stratified confidence intervals** As a final example, we refine the analysis above by considering the difference of mean BMI values between females and males within age bands. We see below that the overall average difference of 1.1 units results from differences that are very different based on age. Specifically, the difference between female and male BMI is much smaller than 1.1 for younger people, and much larger than 1.1 for older people.\n",
    "\n",
    "Since the confidence bands for people under 40 contain 0, the data are consistent with there being no difference between female and male BMI in this age range. For people older than 40, a hypothetical zero difference between the mean BMI values for females and males is not very consistent with the data. Informally, we can say that the data strongly suggest that the female mean BMI is greater than the male mean BMI in this age band, with the difference being anywhere from 0.5 to 2 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327eb4fb-847d-4dde-96ad-bb0b62186b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, SD, and sample size for BMI within age/gender groups\n",
    "df[\"agegrp\"] = pd.cut(df.RIDAGEYR, [18, 30, 40, 50, 60, 70, 80])\n",
    "pr = df.groupby([\"agegrp\", \"RIAGENDRx\"]).agg({\"BMXBMI\": [np.mean, np.std, np.size]}).unstack()\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e413c-92b7-4d79-a83d-b4b1a5136edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the SEM for females and for males within each age band\n",
    "pr[\"BMXBMI\", \"sem\", \"Female\"] = pr[\"BMXBMI\", \"std\", \"Female\"] / np.sqrt(pr[\"BMXBMI\", \"size\", \"Female\"]) \n",
    "pr[\"BMXBMI\", \"sem\", \"Male\"] = pr[\"BMXBMI\", \"std\", \"Male\"] / np.sqrt(pr[\"BMXBMI\", \"size\", \"Male\"]) \n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b83537-38e3-47a3-83f8-ec55b7108b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean difference of BMI between females and males within each age band, also  calculate\n",
    "# its SE and the lower and upper limits of its 95% CI.\n",
    "pr[\"BMXBMI\", \"mean_diff\", \"test\"] = pr[\"BMXBMI\", \"mean\", \"Female\"] - pr[\"BMXBMI\", \"mean\", \"Male\"]\n",
    "pr[\"BMXBMI\", \"sem_diff\", \"\"] = np.sqrt(pr[\"BMXBMI\", \"sem\", \"Female\"]**2 + pr[\"BMXBMI\", \"sem\", \"Male\"]**2) \n",
    "pr[\"BMXBMI\", \"lcb_diff\", \"\"] = pr[\"BMXBMI\", \"mean_diff\", \"\"] - 1.96 * pr[\"BMXBMI\", \"sem_diff\", \"\"] \n",
    "pr[\"BMXBMI\", \"ucb_diff\", \"\"] = pr[\"BMXBMI\", \"mean_diff\", \"\"] + 1.96 * pr[\"BMXBMI\", \"sem_diff\", \"\"] \n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean difference in black and the confidence limits in blue\n",
    "\n",
    "x1 = np.arange(pr.shape[0])\n",
    "pp = sns.pointplot(data = pr, x=x1, y = pr[\"BMXBMI\", \"mean_diff\", \"\"], color='black')\n",
    "sns.pointplot(data = pr, x=x1, y = pr[\"BMXBMI\", \"lcb_diff\", \"\"], color='blue')\n",
    "sns.pointplot(data = pr, x=x1, y = pr[\"BMXBMI\", \"ucb_diff\", \"\"], color='blue')\n",
    "pp.set_xticklabels(pr.index)\n",
    "pp.set_xlabel(\"Age group\")\n",
    "pp.set_ylabel(\"Female - male BMI difference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc5bd8",
   "metadata": {},
   "source": [
    "**Inter-group and intra-group differences**: As the sample size grows, estimates become increasingly precise, but it is important to remember that a highly precise estimate for the mean does not imply that individuals within a population do not vary from each other. To put the differences shown above in context, below we show the underlying summaries on which the plot above was based. Note that the standard deviation of BMI within both females and males ranges from around 5 to around 8 depending on the age band. This means, for example, that two randomly-selected males will tend to have BMI values that differ by around 6 units. This is a far greater difference than the mean difference of up to around 1.5 BMI units between females and males. Thus, while there is a tendency for females to have slightly higher BMI than males, the heterogeneity within genders is substantially greater than the difference of means between genders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583b840",
   "metadata": {},
   "source": [
    "# Hypothesis Testing on NHANES Data\n",
    "\n",
    "Hypothesis testing is a critical tool in determing what the value of a parameter could be.\n",
    "\n",
    "We know that the basis of our testing has two attributes:\n",
    "\n",
    "**Null Hypothesis: $H_0$**\n",
    "\n",
    "**Alternative Hypothesis: $H_a$**\n",
    "\n",
    "The tests we have discussed above are:\n",
    "\n",
    "* One Population Proportion\n",
    "* Difference in Population Proportions\n",
    "* One Population Mean\n",
    "* Difference in Population Means\n",
    "\n",
    "We will introduce some functions that are extremely useful when calculating a t-statistic and p-value for a hypothesis test.\n",
    "\n",
    "Let's quickly review the following ways to calculate a test statistic for the tests listed above.\n",
    "\n",
    "The equation is:\n",
    "\n",
    "$$\\frac{Best\\ Estimate - Hypothesized\\ Estimate}{Standard\\ Error\\ of\\ Estimate}$$ \n",
    "\n",
    "\n",
    "From this we will get our t-statistic and then we can check a t-table or some program to see the area under that t-statistic and then find the p-value to make our decision on the hypothesis. \n",
    "\n",
    "\n",
    "We will use the examples from our lectures and use python functions to streamline our tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ca723",
   "metadata": {},
   "source": [
    "### Hypothesis Tests for One Proportion\n",
    "\n",
    "The most basic hypothesis test may be the one-sample test for a proportion.  This test is used if we have specified a particular value as the null value for the proportion, and we wish to assess if the data are compatible with the true parameter value being equal to this specified value.  One-sample tests are not used very often in practice, because it is not very common that we have a specific fixed value to use for comparison. For illustration, imagine that the rate of lifetime smoking in another country was known to be 40%, and we wished to assess whether the rate of lifetime smoking in the US were different from 40%.  In the following notebook cell, we carry out the (two-sided) one-sample test that the population proportion of smokers is 0.4, and obtain a p-value of 0.43.  This indicates that the NHANES data are compatible with the proportion of (ever) smokers in the US being 40%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.SMQ020x.dropna() == \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b24e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x.mean()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = np.sqrt(.4 * (1 - .4)/ len(x))\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat = (p - 0.4) / se\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = 2 * dist.norm.cdf(-np.abs(test_stat))\n",
    "print(test_stat, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ba93d",
   "metadata": {},
   "source": [
    "### Hypothesis Tests for Two Proportions\n",
    "\n",
    "Comparative tests tend to be used much more frequently than tests comparing one population to a fixed value.  A two-sample test of proportions is used to assess whether the proportion of individuals with some trait differs between two sub-populations.  For example, we can compare the smoking rates between females and males. Since smoking rates vary strongly with age, we do this in the subpopulation of people between 20 and 25 years of age.  In the cell below, we carry out this test without using any libraries, implementing all the test procedures covered elsewhere in the course using Python code.  We find that the smoking rate for men is around 10 percentage points greater than the smoking rate for females, and this difference is statistically significant (the p-value is around 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066239d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df[[\"SMQ020x\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\n",
    "\n",
    "dx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbde3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dx.groupby(\"RIAGENDRx\")[\"SMQ020x\"].agg([lambda z: np.mean(z == \"Yes\"), \"size\"])\n",
    "p.columns = [\"Smoke\", \"N\"]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d56a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_comb = (dx.SMQ020x == \"Yes\").mean()\n",
    "va = p_comb * (1 - p_comb)\n",
    "\n",
    "se = np.sqrt(va * (1 / p.N.Female + 1 / p.N.Male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284325bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_comb, va, se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat = (p.Smoke.Female - p.Smoke.Male) / se\n",
    "p_value = 2 * dist.norm.cdf(-np.abs(test_stat))\n",
    "(test_stat, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3004ee",
   "metadata": {},
   "source": [
    "### Hypothesis Tests Comparing Means\n",
    "\n",
    "Tests of means are similar in many ways to tests of proportions.  Just as with proportions, for comparing means there are one and two-sample tests, z-tests and t-tests, and one-sided and two-sided tests.  As with tests of proportions, one-sample tests of means are not very common.\n",
    "\n",
    "In the cell below, we carry out a formal test of the null hypothesis that the mean blood pressure for women between the ages of 50 and 60 is equal to the mean blood pressure of men between the ages of 50 and 60. The results indicate that while the mean systolic blood pressure for men is slightly greater than that for women (129 mm/Hg versus 128 mm/Hg), this difference is not statistically significant.\n",
    "\n",
    "There are a number of different variants on the two-sample t-test. Two often-encountered variants are the t-test carried out using the t-distribution, and the t-test carried out using the normal approximation to the reference distribution of the test statistic, often called a z-test. Below we display results from both these testing approaches. When the sample size is large, the difference between the t-test and z-test is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = df[[\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDRx\"]].dropna()\n",
    "dx = dx.loc[(dx.RIDAGEYR >= 50) & (dx.RIDAGEYR <= 60), :]\n",
    "dx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpx_female = dx.loc[dx.RIAGENDRx==\"Female\", \"BPXSY1\"]\n",
    "bpx_male = dx.loc[dx.RIAGENDRx==\"Male\", \"BPXSY1\"]\n",
    "print(bpx_female.mean(), bpx_male.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.stats.ztest(bpx_female, bpx_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10863a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.stats.ztest(dx.BPXSY1, value=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7131413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.stats.ttest_ind(bpx_female, bpx_male))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
